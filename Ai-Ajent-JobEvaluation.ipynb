{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e63c5a9-54ff-4551-9642-d81e1f43f4cf",
   "metadata": {},
   "source": [
    "# Agent_Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1607a7-8f20-4ac2-9eae-5b784803ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "AGENT_GRAPH.PY â€” CORE ORCHESTRATION FILE\n",
    "=======================================\n",
    "\n",
    "This is the MAIN file of the project.\n",
    "This is the only file you actually RUN from the terminal.\n",
    "\n",
    "Everything else (job discovery, LLM reasoning, email sending)\n",
    "exists to SUPPORT this file.\n",
    "\n",
    "Think of this file as:\n",
    "- the brain\n",
    "- the workflow controller\n",
    "- the traffic police for the agent\n",
    "\n",
    "If you understand this file, you understand the project.\n",
    "\"\"\"\n",
    "\n",
    "# LangGraph is used to build agent workflows as graphs instead of chains\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# TypedDict is used to clearly define the agent's shared memory (state)\n",
    "from typing import TypedDict, List, Dict, Any\n",
    "\n",
    "# External module that fetches raw job postings\n",
    "from job_discovery import get_jobs\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# AGENT STATE (SHARED MEMORY)\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "AgentState defines EVERYTHING the agent knows at any point in time.\n",
    "\n",
    "LangGraph forces us to be explicit about state.\n",
    "This avoids hidden variables and makes debugging much easier.\n",
    "\n",
    "Every node:\n",
    "- receives this state\n",
    "- modifies it\n",
    "- returns it\n",
    "\"\"\"\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    jobs: List[Dict[str, Any]]           # jobs currently under consideration\n",
    "    skipped_jobs: List[Dict[str, Any]]   # jobs rejected + reason\n",
    "    roles_targeted: List[str]            # user preferences\n",
    "    max_experience_allowed: int          # user constraint\n",
    "    decisions: List[Dict[str, Any]]      # final agent decisions\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# CREATE THE GRAPH\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "StateGraph is LangGraph's main abstraction.\n",
    "We tell it what the shared state looks like.\n",
    "\"\"\"\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# NODE 1 â€” JOB DISCOVERY\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "This node is responsible for bringing EXTERNAL DATA into the agent.\n",
    "\n",
    "Important design choice:\n",
    "- The agent does NOT scrape websites itself.\n",
    "- It receives already-structured job data from job_discovery.py\n",
    "\n",
    "This keeps responsibilities clean.\n",
    "\"\"\"\n",
    "\n",
    "def discover_jobs_node(state: AgentState) -> AgentState:\n",
    "    result = get_jobs()   # expected to return a dictionary\n",
    "\n",
    "    # Inject discovered jobs into agent memory\n",
    "    state[\"jobs\"] = result[\"jobs\"]\n",
    "\n",
    "    # Jobs skipped during scraping phase (duplicates, broken posts, etc.)\n",
    "    state[\"skipped_jobs\"] = result[\"skipped_jobs\"]\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# NODE 2 â€” MASKED COMPANY FILTER\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "Some job postings hide company names using '*'.\n",
    "These are often spammy or low quality.\n",
    "\n",
    "Instead of deleting them:\n",
    "- we skip them\n",
    "- we STORE the reason\n",
    "\n",
    "This helps with transparency and reporting.\n",
    "\"\"\"\n",
    "\n",
    "def check_masked_node(state: AgentState) -> AgentState:\n",
    "    clean_jobs = []\n",
    "    skipped = state[\"skipped_jobs\"]\n",
    "\n",
    "    for job in state[\"jobs\"]:\n",
    "        if \"*\" in job[\"title\"] or \"*\" in job[\"company\"]:\n",
    "            skipped.append({\n",
    "                \"title\": job[\"title\"],\n",
    "                \"company\": job[\"company\"],\n",
    "                \"reason\": \"masked_company\"\n",
    "            })\n",
    "        else:\n",
    "            clean_jobs.append(job)\n",
    "\n",
    "    state[\"jobs\"] = clean_jobs\n",
    "    state[\"skipped_jobs\"] = skipped\n",
    "    return state\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# NODE 3 â€” ROLE MATCHING\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "Before using LLMs, we apply cheap rule-based filters.\n",
    "\n",
    "Why?\n",
    "- Faster\n",
    "- Cheaper\n",
    "- Avoids unnecessary LLM calls\n",
    "\n",
    "Here we check whether the job title matches\n",
    "the roles defined in user_profile.json.\n",
    "\"\"\"\n",
    "\n",
    "def check_role_node(state: AgentState) -> AgentState:\n",
    "    clean_jobs = []\n",
    "    skipped = state[\"skipped_jobs\"]\n",
    "\n",
    "    roles = [r.lower() for r in state[\"roles_targeted\"]]\n",
    "\n",
    "    for job in state[\"jobs\"]:\n",
    "        title = job[\"title\"].lower()\n",
    "\n",
    "        if any(role in title for role in roles):\n",
    "            clean_jobs.append(job)\n",
    "        else:\n",
    "            skipped.append({\n",
    "                \"title\": job[\"title\"],\n",
    "                \"company\": job[\"company\"],\n",
    "                \"reason\": \"role_mismatch\"\n",
    "            })\n",
    "\n",
    "    state[\"jobs\"] = clean_jobs\n",
    "    state[\"skipped_jobs\"] = skipped\n",
    "    return state\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# NODE 4 â€” EXPERIENCE FILTER\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "This node enforces experience constraints.\n",
    "\n",
    "Applying for roles far above experience level\n",
    "is usually a waste of time.\n",
    "\n",
    "We filter early to protect the user.\n",
    "\"\"\"\n",
    "\n",
    "def check_experience_node(state: AgentState) -> AgentState:\n",
    "    clean_jobs = []\n",
    "    skipped = state[\"skipped_jobs\"]\n",
    "    max_exp = state[\"max_experience_allowed\"]\n",
    "\n",
    "    for job in state[\"jobs\"]:\n",
    "        required = job.get(\"required_experience\")\n",
    "\n",
    "        if required is not None and required > max_exp:\n",
    "            skipped.append({\n",
    "                \"title\": job[\"title\"],\n",
    "                \"company\": job[\"company\"],\n",
    "                \"required_experience\": required,\n",
    "                \"reason\": \"experience_too_high\"\n",
    "            })\n",
    "        else:\n",
    "            clean_jobs.append(job)\n",
    "\n",
    "    state[\"jobs\"] = clean_jobs\n",
    "    state[\"skipped_jobs\"] = skipped\n",
    "    return state\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# NODE 5 â€” FINAL DECISION\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "At this stage, only high-quality jobs remain.\n",
    "\n",
    "This node creates the final \"apply\" decisions.\n",
    "Later modules (LLM reasoning, email reporting)\n",
    "use this output.\n",
    "\"\"\"\n",
    "\n",
    "def decide_apply_node(state: AgentState) -> AgentState:\n",
    "    decisions = []\n",
    "\n",
    "    for job in state[\"jobs\"]:\n",
    "        decisions.append({\n",
    "            \"title\": job[\"title\"],\n",
    "            \"company\": job[\"company\"],\n",
    "            \"decision\": \"apply\"\n",
    "        })\n",
    "\n",
    "    state[\"decisions\"] = decisions\n",
    "    return state\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# REGISTER NODES IN GRAPH\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "Nodes must be registered with the graph.\n",
    "Each node is a named step.\n",
    "\"\"\"\n",
    "\n",
    "graph.add_node(\"discover_jobs\", discover_jobs_node)\n",
    "graph.add_node(\"check_masked\", check_masked_node)\n",
    "graph.add_node(\"check_role\", check_role_node)\n",
    "graph.add_node(\"check_experience\", check_experience_node)\n",
    "graph.add_node(\"decide_apply\", decide_apply_node)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# DEFINE EXECUTION FLOW\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "This is where LangGraph becomes powerful.\n",
    "\n",
    "We explicitly define:\n",
    "- where the agent starts\n",
    "- the order of execution\n",
    "- where it ends\n",
    "\"\"\"\n",
    "\n",
    "graph.set_entry_point(\"discover_jobs\")\n",
    "graph.add_edge(\"discover_jobs\", \"check_masked\")\n",
    "graph.add_edge(\"check_masked\", \"check_role\")\n",
    "graph.add_edge(\"check_role\", \"check_experience\")\n",
    "graph.add_edge(\"check_experience\", \"decide_apply\")\n",
    "graph.add_edge(\"decide_apply\", END)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# COMPILE GRAPH\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "Compilation converts the graph definition\n",
    "into an executable agent.\n",
    "\"\"\"\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# RUN THE AGENT\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "This is the ONLY thing you run from terminal:\n",
    "\n",
    "python agent_graph.py\n",
    "\n",
    "Everything else happens automatically.\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    initial_state = {\n",
    "        \"jobs\": [],\n",
    "        \"skipped_jobs\": [],\n",
    "        \"roles_targeted\": [\"ai engineer\", \"machine learning engineer\"],\n",
    "        \"max_experience_allowed\": 5,\n",
    "        \"decisions\": []\n",
    "    }\n",
    "\n",
    "    result = app.invoke(initial_state)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a20e6b-223a-4b92-a2fa-46b7f6ef9800",
   "metadata": {},
   "source": [
    "# job_discovery.py\n",
    "This is the file that touches the outside world.\n",
    "Everything before was logic. This is data acquisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1217d4a8-443d-4786-8d81-b8b5bae6efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "JOB_DISCOVERY.PY â€” JOB FETCHING & SCRAPING LAYER\n",
    "================================================\n",
    "\n",
    "Purpose of this file:\n",
    "- Go outside the agent\n",
    "- Fetch real job postings\n",
    "- Return structured data\n",
    "\n",
    "IMPORTANT DESIGN IDEA:\n",
    "----------------------\n",
    "The agent itself does NOT scrape the web.\n",
    "This file does.\n",
    "\n",
    "Why?\n",
    "- Separation of concerns\n",
    "- Easier debugging\n",
    "- Easier replacement later (API instead of scraping)\n",
    "\n",
    "Agent_graph.py does NOT care HOW jobs are fetched.\n",
    "It only cares about the RESULT.\n",
    "\"\"\"\n",
    "\n",
    "from playwright.sync_api import sync_playwright\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# MAIN FUNCTION EXPOSED TO THE AGENT\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "This is the ONLY function agent_graph.py calls from this file.\n",
    "\n",
    "Rule:\n",
    "- If a function is not used by the agent, it should not be exposed.\n",
    "\"\"\"\n",
    "\n",
    "def get_jobs() -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    {\n",
    "        \"jobs\":        list of valid job postings,\n",
    "        \"skipped_jobs\": list of skipped jobs with reasons\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    jobs = []\n",
    "    skipped_jobs = []\n",
    "\n",
    "    # Playwright is used instead of requests/bs4 because:\n",
    "    # - LinkedIn uses heavy JavaScript\n",
    "    # - Pages load dynamically\n",
    "    # - Normal scraping fails\n",
    "    with sync_playwright() as p:\n",
    "        browser = p.chromium.launch(headless=True)\n",
    "        page = browser.new_page()\n",
    "\n",
    "        # NOTE:\n",
    "        # This URL is usually a LinkedIn job search URL\n",
    "        # In practice, it can change often\n",
    "        search_url = \"https://www.linkedin.com/jobs/search/?keywords=ai%20engineer\"\n",
    "\n",
    "        page.goto(search_url, timeout=60000)\n",
    "\n",
    "        # Wait until job cards load\n",
    "        page.wait_for_selector(\"ul.jobs-search__results-list\")\n",
    "\n",
    "        job_cards = page.query_selector_all(\"li.jobs-search-results__list-item\")\n",
    "\n",
    "        for card in job_cards:\n",
    "            try:\n",
    "                title_el = card.query_selector(\"h3\")\n",
    "                company_el = card.query_selector(\"h4\")\n",
    "\n",
    "                # Defensive programming:\n",
    "                # Pages change, elements disappear\n",
    "                if not title_el or not company_el:\n",
    "                    skipped_jobs.append({\n",
    "                        \"reason\": \"missing_title_or_company\"\n",
    "                    })\n",
    "                    continue\n",
    "\n",
    "                title = title_el.inner_text().strip()\n",
    "                company = company_el.inner_text().strip()\n",
    "\n",
    "                # This project intentionally keeps parsing minimal.\n",
    "                # More parsing = more fragility.\n",
    "                jobs.append({\n",
    "                    \"title\": title,\n",
    "                    \"company\": company,\n",
    "\n",
    "                    # Placeholder for later reasoning\n",
    "                    # Some jobs include experience, some don't\n",
    "                    \"required_experience\": None\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                # If ONE job card fails, we do NOT kill the run\n",
    "                skipped_jobs.append({\n",
    "                    \"reason\": \"exception_during_scrape\",\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "\n",
    "        browser.close()\n",
    "\n",
    "    # IMPORTANT:\n",
    "    # We always return the SAME STRUCTURE.\n",
    "    # LangGraph nodes depend on predictable state shape.\n",
    "    return {\n",
    "        \"jobs\": jobs,\n",
    "        \"skipped_jobs\": skipped_jobs\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15672bad-1524-4665-9e9c-efa70138118b",
   "metadata": {},
   "source": [
    "Key mental model (important, read this)\n",
    "\n",
    "job_discovery.py is NOT an agent\n",
    "\n",
    "It has no reasoning\n",
    "\n",
    "It has no LLM\n",
    "\n",
    "It has no decisions\n",
    "\n",
    "It is just:\n",
    "\n",
    "â€œGo get raw jobs and donâ€™t crash.â€\n",
    "\n",
    "If tomorrow you:\n",
    "\n",
    "replace LinkedIn with an API\n",
    "\n",
    "use RSS feeds\n",
    "\n",
    "use Indeed\n",
    "\n",
    "use a paid data source\n",
    "\n",
    "ðŸ‘‰ Only this file changes\n",
    "The agent graph stays intact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5bc6f6-8dbc-44c6-a651-55bc4893b94a",
   "metadata": {},
   "source": [
    "# batch_reasoning.py\n",
    "\n",
    "This is where the project crosses the line from automation to intelligence.\n",
    "Up to now, everything was rules.\n",
    "Here is where LLMs start thinking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fc4a43-f214-4bdd-a8f2-9f372a945f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BATCH_REASONING.PY â€” APPLYING LLM REASONING AT SCALE\n",
    "===================================================\n",
    "\n",
    "Purpose of this file:\n",
    "- Take filtered jobs from the agent\n",
    "- Run LLM reasoning on EACH job\n",
    "- Attach human-readable explanations\n",
    "\n",
    "Why this file exists:\n",
    "--------------------\n",
    "We separate reasoning from orchestration.\n",
    "\n",
    "agent_graph.py:\n",
    "- controls flow\n",
    "- controls order\n",
    "- controls state\n",
    "\n",
    "batch_reasoning.py:\n",
    "- focuses ONLY on \"thinking\"\n",
    "\n",
    "This keeps the agent modular and testable.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# This is the LLM-powered reasoning function\n",
    "from llm_reasoner import explain_job\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# MAIN FUNCTION USED BY THE AGENT\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "This function is used after job filtering is complete.\n",
    "\n",
    "Input:\n",
    "- jobs: list of clean jobs\n",
    "- user_profile: user preferences\n",
    "\n",
    "Output:\n",
    "- enriched job decisions with explanations\n",
    "\"\"\"\n",
    "\n",
    "def evaluate_jobs(\n",
    "    jobs: List[Dict[str, Any]],\n",
    "    user_profile: Dict[str, Any]\n",
    ") -> List[Dict[str, Any]]:\n",
    "    evaluated_jobs = []\n",
    "\n",
    "    for job in jobs:\n",
    "        try:\n",
    "            # Ask the LLM to reason about THIS job\n",
    "            llm_result = explain_job(job, user_profile)\n",
    "\n",
    "            # Combine original job data with LLM reasoning\n",
    "            evaluated_jobs.append({\n",
    "                \"title\": job.get(\"title\"),\n",
    "                \"company\": job.get(\"company\"),\n",
    "                \"required_experience\": job.get(\"required_experience\"),\n",
    "\n",
    "                # LLM outputs\n",
    "                \"decision\": llm_result.get(\"decision\"),\n",
    "                \"reason\": llm_result.get(\"reason\"),\n",
    "                \"focus_keywords\": llm_result.get(\"focus_keywords\")\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            # IMPORTANT DESIGN CHOICE:\n",
    "            # One failed LLM call should NOT kill the whole run.\n",
    "            evaluated_jobs.append({\n",
    "                \"title\": job.get(\"title\"),\n",
    "                \"company\": job.get(\"company\"),\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "\n",
    "    return evaluated_jobs\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# OPTIONAL STANDALONE TEST RUN\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "This block is ONLY for debugging.\n",
    "\n",
    "You do NOT run this in production.\n",
    "You do NOT call this from agent_graph.py.\n",
    "\n",
    "It exists so you can test LLM reasoning\n",
    "WITHOUT running the entire agent.\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from job_discovery import get_jobs\n",
    "\n",
    "    with open(\"user_profile.json\", \"r\") as f:\n",
    "        user_profile = json.load(f)\n",
    "\n",
    "    jobs_data = get_jobs()\n",
    "    jobs = jobs_data[\"jobs\"]\n",
    "\n",
    "    results = evaluate_jobs(jobs, user_profile)\n",
    "\n",
    "    print(json.dumps(results, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d9d1d4-dabb-4429-bf26-89af4864d18d",
   "metadata": {},
   "source": [
    "Key mental model (very important)\n",
    "\n",
    "This file does NOT decide workflow\n",
    "\n",
    "This file does NOT scrape\n",
    "\n",
    "This file does NOT send emails\n",
    "\n",
    "It only answers one question:\n",
    "\n",
    "â€œGiven this job and this user, what does an LLM think?â€\n",
    "\n",
    "Thatâ€™s it.\n",
    "\n",
    "Why this separation matters (real engineering reason)\n",
    "\n",
    "If tomorrow you want to:\n",
    "\n",
    "change the LLM\n",
    "\n",
    "change the prompt\n",
    "\n",
    "add scoring\n",
    "\n",
    "add ranking\n",
    "\n",
    "add feedback loops\n",
    "\n",
    "ðŸ‘‰ You only touch:\n",
    "\n",
    "llm_reasoner.py\n",
    "\n",
    "batch_reasoning.py\n",
    "\n",
    "The agent graph stays untouched."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940a91e4-7416-4a87-a0b8-c757138d6083",
   "metadata": {},
   "source": [
    "# llm_reasoner.py\n",
    "\n",
    "This file is the thinking engine.\n",
    "Everything intelligent in this project lives here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c4c819-1c9f-4e57-bf6f-65f23af85d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LLM_REASONER.PY â€” SINGLE-JOB LLM INTELLIGENCE\n",
    "============================================\n",
    "\n",
    "Purpose of this file:\n",
    "- Ask an LLM to reason about ONE job\n",
    "- Compare it against ONE user profile\n",
    "- Return a structured decision + explanation\n",
    "\n",
    "This file does NOT:\n",
    "- scrape jobs\n",
    "- loop over multiple jobs\n",
    "- send emails\n",
    "- control workflow\n",
    "\n",
    "It answers only one question:\n",
    "\"Should this user apply for THIS job, and why?\"\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# LangChain wrapper for OpenAI-compatible APIs\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Used to load environment variables from .env\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# LOAD ENVIRONMENT VARIABLES\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "This allows us to keep API keys out of the code.\n",
    "\n",
    ".env file contains:\n",
    "OPENROUTER_API_KEY=xxxxxxxx\n",
    "\"\"\"\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# CREATE LLM CLIENT\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "We use OpenRouter instead of OpenAI directly.\n",
    "\n",
    "Why OpenRouter?\n",
    "- Cheaper\n",
    "- Model flexibility\n",
    "- OpenAI-compatible API\n",
    "\n",
    "Even though the class is ChatOpenAI,\n",
    "it works with OpenRouter because the API is compatible.\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"openai/gpt-4o-mini\",  # lightweight, fast, cheap\n",
    "    temperature=0.2,             # low randomness = more consistent reasoning\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\"\n",
    ")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# CORE REASONING FUNCTION\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "This is the ONLY function batch_reasoning.py calls.\n",
    "\n",
    "Input:\n",
    "- job: one job posting\n",
    "- user_profile: resume + preferences\n",
    "\n",
    "Output:\n",
    "A dictionary with:\n",
    "- decision: apply / skip\n",
    "- reason: explanation in plain English\n",
    "- focus_keywords: what the user should improve\n",
    "\"\"\"\n",
    "\n",
    "def explain_job(job: dict, user_profile: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Ask the LLM to reason like a career assistant.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build a clear, explicit prompt\n",
    "    prompt = f\"\"\"\n",
    "You are an AI career assistant.\n",
    "\n",
    "User profile:\n",
    "- Target roles: {user_profile.get(\"roles_targeted\")}\n",
    "- Experience: {user_profile.get(\"experience_years\")} years\n",
    "- Max allowed experience: {user_profile.get(\"max_experience_allowed\")} years\n",
    "\n",
    "Job posting:\n",
    "- Title: {job.get(\"title\")}\n",
    "- Company: {job.get(\"company\")}\n",
    "- Required experience: {job.get(\"required_experience\")}\n",
    "\n",
    "Your task:\n",
    "1. Decide if the user should apply (\"apply\" or \"skip\").\n",
    "2. Explain the decision clearly.\n",
    "3. List missing or important keywords the user should improve.\n",
    "\n",
    "Respond STRICTLY in valid JSON with this structure:\n",
    "{{\n",
    "  \"decision\": \"apply or skip\",\n",
    "  \"reason\": \"short explanation\",\n",
    "  \"focus_keywords\": [\"keyword1\", \"keyword2\"]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    # Send prompt to the LLM\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    # LLMs return text, not Python objects\n",
    "    raw_output = response.content.strip()\n",
    "\n",
    "    # Defensive parsing:\n",
    "    # LLMs sometimes return text before/after JSON\n",
    "    try:\n",
    "        result = json.loads(raw_output)\n",
    "    except json.JSONDecodeError:\n",
    "        # If parsing fails, return a safe fallback\n",
    "        result = {\n",
    "            \"decision\": \"skip\",\n",
    "            \"reason\": \"LLM output could not be parsed safely.\",\n",
    "            \"focus_keywords\": []\n",
    "        }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa24fca-1bf3-4e3e-a597-60a8b4db8102",
   "metadata": {},
   "source": [
    "Key mental model (important)\n",
    "\n",
    "This file reasons about ONE job only\n",
    "\n",
    "It has no loops\n",
    "\n",
    "It has no workflow\n",
    "\n",
    "It has no side effects\n",
    "\n",
    "That makes it:\n",
    "\n",
    "testable\n",
    "\n",
    "replaceable\n",
    "\n",
    "safe\n",
    "\n",
    "If tomorrow you want:\n",
    "\n",
    "better prompts\n",
    "\n",
    "scoring instead of apply/skip\n",
    "\n",
    "multiple reasoning passes\n",
    "\n",
    "different models\n",
    "\n",
    "ðŸ‘‰ You change only this file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a36892-ff72-40bd-980e-672f6fcabaf7",
   "metadata": {},
   "source": [
    "# email_report.py\n",
    "\n",
    "This file is presentation logic.\n",
    "The agent has already decided.\n",
    "The LLM has already reasoned.\n",
    "Now we convert results into something a human can read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70d17a8-8a95-4e63-96c2-ed2f9d0b2864",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EMAIL_REPORT.PY â€” HUMAN-READABLE SUMMARY GENERATION\n",
    "==================================================\n",
    "\n",
    "Purpose of this file:\n",
    "- Take final agent decisions\n",
    "- Convert them into a clean email-friendly report\n",
    "- No scraping, no LLM calls, no workflow logic\n",
    "\n",
    "Think of this file as:\n",
    "\"How do I explain the agentâ€™s output to a human?\"\n",
    "\"\"\"\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# MAIN REPORT GENERATION FUNCTION\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "This function prepares TEXT.\n",
    "It does NOT send the email.\n",
    "It only formats content.\n",
    "\n",
    "Input:\n",
    "- evaluated_jobs: output from batch_reasoning.py\n",
    "\n",
    "Output:\n",
    "- subject: email subject line\n",
    "- body: email body text\n",
    "\"\"\"\n",
    "\n",
    "def generate_email_report(evaluated_jobs: List[Dict]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Build a readable email summary from agent decisions.\n",
    "    \"\"\"\n",
    "\n",
    "    # If no jobs were found or all were skipped\n",
    "    if not evaluated_jobs:\n",
    "        return {\n",
    "            \"subject\": \"Daily Job Agent Report â€” No Matching Jobs\",\n",
    "            \"body\": (\n",
    "                \"Hello,\\n\\n\"\n",
    "                \"Your AI job agent ran successfully today.\\n\"\n",
    "                \"No suitable jobs were found based on your profile.\\n\\n\"\n",
    "                \"This is a confirmation email â€” the system is working.\\n\\n\"\n",
    "                \"Regards,\\n\"\n",
    "                \"Your AI Job Agent\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "    # Email header\n",
    "    body_lines = [\n",
    "        \"Hello,\\n\",\n",
    "        \"Your AI job agent analyzed today's job postings.\\n\",\n",
    "        \"Here are the most relevant opportunities:\\n\"\n",
    "    ]\n",
    "\n",
    "    # Loop through evaluated jobs\n",
    "    for idx, job in enumerate(evaluated_jobs, start=1):\n",
    "        body_lines.append(\n",
    "            f\"{idx}. {job.get('title')} at {job.get('company')}\\n\"\n",
    "        )\n",
    "        body_lines.append(\n",
    "            f\"   Decision: {job.get('decision')}\\n\"\n",
    "        )\n",
    "        body_lines.append(\n",
    "            f\"   Reason: {job.get('reason')}\\n\"\n",
    "        )\n",
    "\n",
    "        keywords = job.get(\"focus_keywords\", [])\n",
    "        if keywords:\n",
    "            body_lines.append(\n",
    "                f\"   Suggested skills to improve: {', '.join(keywords)}\\n\"\n",
    "            )\n",
    "\n",
    "        body_lines.append(\"\\n\")\n",
    "\n",
    "    body_lines.append(\n",
    "        \"This report was generated automatically by your AI agent.\\n\\n\"\n",
    "        \"Regards,\\n\"\n",
    "        \"Your AI Job Agent\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"subject\": \"Daily Job Agent Report â€” Matching Opportunities Found\",\n",
    "        \"body\": \"\".join(body_lines)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae8a8b8-7b3f-4491-9185-3a742622cff1",
   "metadata": {},
   "source": [
    "Key mental model (important)\n",
    "\n",
    "This file does not think\n",
    "\n",
    "This file does not decide\n",
    "\n",
    "This file does not automate\n",
    "\n",
    "It only answers:\n",
    "\n",
    "â€œHow should this look to a human?â€\n",
    "\n",
    "This separation is critical:\n",
    "\n",
    "You can redesign emails without touching the agent\n",
    "\n",
    "You can add HTML later\n",
    "\n",
    "You can add Slack / WhatsApp later\n",
    "\n",
    "Why this file matters in real systems\n",
    "\n",
    "Most AI projects stop at:\n",
    "\n",
    "â€œHereâ€™s some JSON.â€\n",
    "\n",
    "Real systems need:\n",
    "\n",
    "summaries\n",
    "\n",
    "confirmations\n",
    "\n",
    "explanations\n",
    "\n",
    "trust\n",
    "\n",
    "This file provides that bridge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841de972-130a-46a9-a7d8-630411636a1e",
   "metadata": {},
   "source": [
    "# email_sender.py\n",
    "\n",
    "This is the delivery layer.\n",
    "Nothing intelligent happens here.\n",
    "It simply sends what was already prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17c4cbf-979d-472b-a535-1fb47b5383de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EMAIL_SENDER.PY â€” EMAIL DELIVERY LAYER\n",
    "=====================================\n",
    "\n",
    "Purpose of this file:\n",
    "- Take a prepared email report\n",
    "- Send it to the user via Gmail SMTP\n",
    "\n",
    "This file does NOT:\n",
    "- decide anything\n",
    "- reason about jobs\n",
    "- format content\n",
    "\n",
    "It answers ONE question:\n",
    "\"How do we deliver the result to the user?\"\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# LOAD ENVIRONMENT VARIABLES\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "Email credentials are stored in .env for security.\n",
    "\n",
    ".env contains:\n",
    "- SENDER_EMAIL\n",
    "- SENDER_PASSWORD (Gmail App Password)\n",
    "\n",
    "NEVER hardcode credentials.\n",
    "NEVER commit .env to GitHub.\n",
    "\"\"\"\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# MAIN EMAIL SENDING FUNCTION\n",
    "# -------------------------------------------------------------------\n",
    "\"\"\"\n",
    "This function is called by the agent after the report is generated.\n",
    "\n",
    "Input:\n",
    "- subject: email subject\n",
    "- body: email body text\n",
    "- receiver_email: where to send the email\n",
    "\"\"\"\n",
    "\n",
    "def send_email(subject: str, body: str, receiver_email: str) -> None:\n",
    "    sender_email = os.getenv(\"SENDER_EMAIL\")\n",
    "    sender_password = os.getenv(\"SENDER_PASSWORD\")\n",
    "\n",
    "    # Basic validation\n",
    "    if not sender_email or not sender_password:\n",
    "        raise ValueError(\"Email credentials not found in environment variables.\")\n",
    "\n",
    "    # Create email object\n",
    "    message = MIMEMultipart()\n",
    "    message[\"From\"] = sender_email\n",
    "    message[\"To\"] = receiver_email\n",
    "    message[\"Subject\"] = subject\n",
    "\n",
    "    # Attach email body as plain text\n",
    "    message.attach(MIMEText(body, \"plain\"))\n",
    "\n",
    "    # Gmail SMTP configuration\n",
    "    smtp_server = \"smtp.gmail.com\"\n",
    "    smtp_port = 587\n",
    "\n",
    "    try:\n",
    "        # Connect to Gmail SMTP\n",
    "        server = smtplib.SMTP(smtp_server, smtp_port)\n",
    "        server.starttls()  # Secure connection\n",
    "        server.login(sender_email, sender_password)\n",
    "\n",
    "        # Send email\n",
    "        server.send_message(message)\n",
    "        server.quit()\n",
    "\n",
    "        print(\"Email sent successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Failed to send email.\")\n",
    "        print(str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd6862d-51e2-49a3-92ee-bfb2378ab56c",
   "metadata": {},
   "source": [
    "Mental model (very important)\n",
    "\n",
    "This file is replaceable\n",
    "\n",
    "You could swap Gmail for:\n",
    "\n",
    "AWS SES\n",
    "\n",
    "SendGrid\n",
    "\n",
    "Slack\n",
    "\n",
    "WhatsApp\n",
    "\n",
    "Telegram\n",
    "\n",
    "And the rest of the project would remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2479021a-2a6e-45c4-8b45-7f0e2a6e180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python agent_graph.py    (terminal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168e30c8-127f-4ef4-ae1e-08212cf58a26",
   "metadata": {},
   "source": [
    "# Big picture (tie everything together)\n",
    "\n",
    "job_discovery.py â†’ gets raw jobs\n",
    "\n",
    "agent_graph.py â†’ controls the agent workflow (LangGraph)\n",
    "\n",
    "batch_reasoning.py â†’ applies LLM reasoning at scale\n",
    "\n",
    "llm_reasoner.py â†’ single-job intelligence\n",
    "\n",
    "email_report.py â†’ human-readable summary\n",
    "\n",
    "email_sender.py â†’ delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86330c5c-d3be-4d05-83d0-4d7e2615e0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15408ad6-7340-4dac-83d1-0249d2ced1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
